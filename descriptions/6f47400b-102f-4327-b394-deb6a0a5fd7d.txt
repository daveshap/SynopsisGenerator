Keywords: GPT3 error: This model's maximum context length is 4097 tokens, however you requested 4138 tokens (1138 in your prompt; 3000 for the completion). Please reduce your prompt; or completion length. 
Description: GPT3 error: This model's maximum context length is 4097 tokens, however you requested 4136 tokens (1136 in your prompt; 3000 for the completion). Please reduce your prompt; or completion length.